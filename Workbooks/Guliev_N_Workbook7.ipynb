{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b282a6a3c8674da6854d06e6a85404cc","deepnote_cell_type":"text-cell-h2","formattedRanges":[]},"source":["## Рабочая тетрадь №7"]},{"cell_type":"markdown","metadata":{"cell_id":"afe71d6c9bde456a9516e62bb46f69f5","deepnote_cell_type":"markdown"},"source":["### 1.1.1 Пример\n","Рассмотрим программу обучения персептрона на языке Python. Сначала рассмотрим основной класс персептрона, который умеет учиться по тестовым данным."]},{"cell_type":"code","execution_count":57,"metadata":{"cell_id":"7f31dcdd4eb04a31b8b811cb2dab67f4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":9,"execution_start":1686039495396,"source_hash":"79a5c1a8"},"outputs":[],"source":["# класс, который реализует перспептрон и его обучение\n","class Perceptron:\n","    def __init__(self,N):\n","        # создать нулевые веса\n","        self.w = list()\n","        for i in range(N):\n","            self.w.append(0)\n","    #метод для вычисления значения перспептрона\n","    def calc(self,x):\n","        res = 0\n","        for i in range(len(self.w)):\n","            res = res + self.w[i] * x[i]\n","        return res\n","    # пороговая функция активации перспептрона\n","    def sign(self,x):\n","        if self.calc(x) > 0:\n","            return 1\n","        else:\n","            return -1\n","    # обучение на одном примере\n","    def learn(self, la, x, y):\n","        #обучаем только, когда результат неверный\n","        if y * self.calc(x) <= 0:\n","            for i in range(len(self.w)):\n","                self.w[i] = self.w[i] + la * y * x[i]\n","    #обучение по всем данным Т - кортеж примеров\n","    def learning(self, la, T):\n","        #цикл обучения\n","        for n in range(100):\n","            #обучение по всем набору примеров\n","            for t in T:\n","                self.learn(la,t[0], t[1])"]},{"cell_type":"markdown","metadata":{"cell_id":"a02fc7121e8444bea34f593672485b70","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["В строке 25 мы осуществляем корректировку весов. Посмотрим, как учится\n","и работает наш персептрон."]},{"cell_type":"code","execution_count":58,"metadata":{"cell_id":"4e747925788147c89b140436f2cafbfb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":22,"execution_start":1686039495460,"source_hash":"809a027b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.1, -0.1]\n","-1\n","1\n","1\n","-1\n"]}],"source":["# создаем класс двумерного перспетрона\n","perceptron = Perceptron(2)\n","la = 0.1 # константа обучения\n","# создаём примеры\n","T = list()\n","T.append([[2,1],1])\n","T.append([[3,2],1])\n","T.append([[4,1],1])\n","T.append([[1,2],-1])\n","T.append([[2,3],-1])\n","T.append([[5,7],-1])\n","perceptron.learning(la,T) # обучение перспетрона\n","print(perceptron.w) # печатаем веса\n","# проверим работу на тестовых примерах\n","print(perceptron.sign([1.5, 2]))\n","print(perceptron.sign([3, 1.5]))\n","print(perceptron.sign([5, 1]))\n","print(perceptron.sign([5, 10]))"]},{"cell_type":"markdown","metadata":{"cell_id":"c6fb342894a84f56a1c14fc4e19052b5","deepnote_cell_type":"markdown"},"source":["Видим, что что наш персептрон отлично научился распознавать образы, относя к классу 1 те вектора, у которых первая компонента больше второй, и к классу -1 в противном случае. Хотя устройство персептронов довольно простое эти конструкции могут решать и практические задачи. Кроме того, из таких персептронов состоят нейронные сети."]},{"cell_type":"markdown","metadata":{"cell_id":"e2d8737a17644c7ea69036455268dae8","deepnote_cell_type":"markdown"},"source":["### 1.1.2 Пример\n","Для написания кода нейрона будем использовать библиотеку Pytnon — NumPy:"]},{"cell_type":"code","execution_count":59,"metadata":{"cell_id":"b8e78a0654aa4e349f6762ce048d6378","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":33,"execution_start":1686039495549,"source_hash":"53b664a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9990889488055994\n"]}],"source":["import numpy as np\n","def sigmoid(x):\n","    # Функция активации: f(x) = 1 / (1 + e*(-x))\n","    return 1 / (1 + np.exp(-x))\n","class Neuron:\n","    def __init__(self, weights, bias):\n","        self.weights = weights\n","        self.bias = bias\n","    def feedforward(self, inputs):\n","        total = np.dot(self.weights, inputs) + self.bias\n","        return sigmoid(total)\n","\n","weights = np.array([0, 1])  # w1 = 0, w2 = 1\n","bias = 4                    # с = 4\n","n = Neuron(weights, bias)\n","x = np.array([2, 3])        # x = 2, y = 3\n","print(n.feedforward(x))     # 0.9990889488055994"]},{"cell_type":"markdown","metadata":{"cell_id":"77e5a28a9f8c4875b1a384f022f5d701","deepnote_cell_type":"markdown"},"source":["Нейросеть состоит из множества соединенных между собой нейронов.\n","Пример несложной нейронной сети\n","\n","![img](https://i.ibb.co/0Cpmr9y/image.png)\n","\n","где:\n","- x1, x2 — входной слой;\n","- h1, h2 — скрытый слой с двумя нейронами;\n","- o1 — выходной слой.\n","Например. Представим, что нейроны из графика выше имеют веса [0, 1]. Пороговое значение (b) у обоих нейронов равно 0 и они имеют идентичную сигмоиду.\n","\n","При входных данных x = [2, 3] получим:\n","\n","![img](https://i.ibb.co/m4wBZ4d/image.png)\n","\n","Входные данные по нейронам передаются до тех пор, пока не получатся выходные значения."]},{"cell_type":"code","execution_count":60,"metadata":{"cell_id":"1c356e58f5df4447930c559304bc01df","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":75,"execution_start":1686039495648,"source_hash":"4d38967e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7216325609518421\n"]}],"source":["import numpy as np\n","class OurNeuralNetwork:\n","    \n","   \n","    def __init__(self):\n","        weights = np.array([0, 1])\n","        bias = 0\n","        # Knacc Neuron u3 предыдущего раздела\n","        self.h1 = Neuron(weights, bias)\n","        self.h2 = Neuron(weights, bias)\n","        self.o1 = Neuron(weights, bias)\n","    def feedforward(self, x):\n","        out_h1 = self.h1.feedforward(x)\n","        out_h2 = self.h2.feedforward(x)\n","        # Входы для o1 — это входы h1 и h2\n","        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n","        return out_o1\n","\n","network = OurNeuralNetwork()\n","x = np.array([2, 3])\n","print(network.feedforward(x)) # 0.7216325609518421"]},{"cell_type":"markdown","metadata":{"cell_id":"2ffbb936b3cb4340bb0a7f12b21599a3","deepnote_cell_type":"markdown"},"source":["### Задание (1.1.2)\n","Реализовать классы нейросетей по аналогии с классом OurNeuralNetwork.\n","Данные нейросети:\n","- три входа (x1, x2, x3);\n","- три нейрона в скрытых слоях (h1, h2, h3);\n","- выход (o1)\n","\n","Нейроны имеют идентичные веса и пороги:\n","- w = [0.5, 0.5, 0.5]\n","- b = 0\n","\n","Данные нейросети:\n","- два входа (x1, x2);\n","- два нейрона в скрытых слоях (h1, h2);\n","- два выхода (o1, o2)\n","\n","Нейроны имеют идентичные веса и пороги:\n","- w = [1, 0];\n","- b = 1"]},{"cell_type":"code","execution_count":61,"metadata":{"cell_id":"7894a000e84d445eb759581982054b23","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":82,"execution_start":1686039495769,"source_hash":"80d5f41f"},"outputs":[],"source":["def sigmoid(x):\n","    # Функция активации: f(x) = 1 / (1 + e*(-x))\n","    return 1 / (1 + np.exp(-x))\n","class Neuron:\n","    def __init__(self, weights, bias):\n","        self.weights = weights\n","        self.bias = bias\n","    def feedforward(self, inputs):\n","        total = np.dot(self.weights, inputs) + self.bias\n","        return sigmoid(total)"]},{"cell_type":"code","execution_count":62,"metadata":{"cell_id":"33847dd6f53146ee83f83ecfe93fe80a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1686039495924,"source_hash":"5e4f4d3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8174507761690052\n"]}],"source":["class OurNeuralNetwork1:\n","    def __init__(self):\n","        weights = np.array([0.5, 0.5, 0.5])\n","        bias = 0\n","        # Knacc Neuron u3 предыдущего раздела\n","        self.h1 = Neuron(weights, bias) # 1 нейрон\n","        self.h2 = Neuron(weights, bias) # 2 нейрон\n","        self.h3 = Neuron(weights, bias) # 3 нейрон\n","        self.o1 = Neuron(weights, bias) # выход\n","    def feedforward(self, x):\n","        out_h1 = self.h1.feedforward(x)\n","        out_h2 = self.h2.feedforward(x)\n","        out_h3 = self.h2.feedforward(x)\n","        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n","        return out_o1\n","\n","network = OurNeuralNetwork1()\n","x = np.array([10, 2, 3])\n","print(network.feedforward(x))"]},{"cell_type":"code","execution_count":63,"metadata":{"cell_id":"0e3642662a974a3397611bdb8b89fd41","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":50,"execution_start":1686039495925,"source_hash":"bc047e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(0.8757270529783324, 0.8757270529783324)\n"]}],"source":["class OurNeuralNetwork2:\n","    def __init__(self):\n","        weights = np.array([1, 0])\n","        bias = 1\n","        # Knacc Neuron u3 предыдущего раздела\n","        self.h1 = Neuron(weights, bias) # 1 нейрон\n","        self.h2 = Neuron(weights, bias) # 2 нейрон\n","        self.o1 = Neuron(weights, bias) # 1 выход\n","        self.o2 = Neuron(weights, bias) # 2 выход\n","    def feedforward(self, x):\n","        out_h1 = self.h1.feedforward(x)\n","        out_h2 = self.h2.feedforward(x)\n","        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n","        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n","        return out_o1, out_o2\n","\n","network = OurNeuralNetwork2()\n","x = np.array([2, 3])\n","print(network.feedforward(x))"]},{"cell_type":"markdown","metadata":{"cell_id":"f2ab55bc2f2544b5a544ddee34fc9461","deepnote_cell_type":"markdown"},"source":["### Задание\n","Реализуйте классы нейронных сетей с использованием других функций активации.\n","\n","![img](https://i.ibb.co/Ln939nY/image.png)"]},{"cell_type":"code","execution_count":64,"metadata":{"cell_id":"ee2d333f5481472eb7b8202c61668202","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1686039495973,"source_hash":"9c59a9a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8174507761690052\n","(0.8757270529783324, 0.8757270529783324)\n"]}],"source":["def sigmoid(x):\n","    sig = 1 / (1 + np.exp(-x))\n","    return sig\n","\n","class Neuron:\n","    def __init__(self, weights, bias):\n","        self.weights = weights\n","        self.bias = bias\n","    def feedforward (self, inputs):\n","        total = np.dot(self.weights, inputs) + self.bias\n","        return sigmoid(total)\n","\n","\n","\n","network = OurNeuralNetwork1()\n","x = np.array ([10, 2, 3])\n","print (network.feedforward(x))\n","\n","network = OurNeuralNetwork2()\n","x = np.array ([2, 3])\n","print (network.feedforward(x))"]},{"cell_type":"code","execution_count":65,"metadata":{"cell_id":"32e8bbe1fe2f405889bbfa77aeeeaf9c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":21,"execution_start":1686039495988,"source_hash":"732c220b"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9051480878090389\n","(0.9636765235959711, 0.9636765235959711)\n"]}],"source":["def tanh(x):\n","    return np.tanh(x)\n","\n","class Neuron:\n","    def __init__(self, weights, bias):\n","        self.weights = weights\n","        self.bias = bias\n","    def feedforward (self, inputs):\n","        total = np.dot(self.weights, inputs) + self.bias\n","        return tanh(total)\n","\n","\n","\n","network = OurNeuralNetwork1()\n","x = np.array ([10, 2, 3])\n","print (network.feedforward(x))\n","\n","network = OurNeuralNetwork2()\n","x = np.array ([2, 3])\n","print (network.feedforward(x))"]},{"cell_type":"code","execution_count":66,"metadata":{"cell_id":"e72c4f65407a494284d57ddac7ef7977","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":47,"execution_start":1686039496052,"source_hash":"6020d016"},"outputs":[{"name":"stdout","output_type":"stream","text":["11.25\n","(4, 4)\n"]}],"source":["def ReLU(x):\n","    return x*(x>0)\n","\n","class Neuron:\n","    def __init__(self, weights, bias):\n","        self.weights = weights\n","        self.bias = bias\n","    def feedforward (self, inputs):\n","        total = np.dot(self.weights, inputs) + self.bias\n","        return ReLU(total)\n","\n","\n","\n","network = OurNeuralNetwork1()\n","x = np.array ([10, 2, 3])\n","print (network.feedforward(x))\n","\n","network = OurNeuralNetwork2()\n","x = np.array ([2, 3])\n","print (network.feedforward(x))"]},{"cell_type":"markdown","metadata":{"cell_id":"a05a80462c1d4d5db112c67ea304ff44","deepnote_cell_type":"markdown"},"source":["### Задание\n","Используйте классы MLPClassified и MLPRegressor для классификации и регрессии произвольных данных из интернета. Проведите анализ атрибуты, полученных моделей.\n","\n","Для классификации можете взять набор данных Ирисов:\n","https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n","\n","а для регрессии датасет зависимости заработной платы от опыта работы:\n","\n","https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv"]},{"cell_type":"markdown","metadata":{"cell_id":"6a1cc68c4910434da424eaaaf1405a97","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["MLPClassifier — это класс, доступный как часть модуля neuro_network\n","sklearn для выполнения задач классификации с использованием\n","многослойного персептрона."]},{"cell_type":"code","execution_count":67,"metadata":{"cell_id":"d99438dadaff49be8f290258ea71ece0","deepnote_app_is_output_hidden":true,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2010,"execution_start":1686039496097,"is_output_hidden":false,"source_hash":"10220a2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset Size:  (150, 4) (150,)\n","(120, 4) (30, 4) (120,) (30,)\n"]}],"source":["# MLPClassifier — это клвсс, доступный как часть модуля neuro_network\n","# sklearn для выполнения задач классификации с использованием\n","# многослойного персептрона.\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n","df = pd.read_csv(url)\n","df.head(5)\n","df\n","df = df.rename(columns={'variety': 'target'})\n","X_df, Y_df = df.drop(['target'], axis=1), df.target\n","print('Dataset Size: ', X_df.shape, Y_df.shape)\n","# Функция train_test_split модуля model_selection sklearn поможет нам\n","# разделить данные на два набора: 80% для обучения и 20% для тестирования.\n","# Мы также используем seed(random_state=123) с train_test_split, чтобы мы\n","# всегда получали одно и то же разделение и могли сравнивать и\n","# воспроизволить результаты в будущем.\n","X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, train_size=0.80, test_size=0.20, stratify=Y_df, random_state=123)\n","print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n"," 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n"," 'Virginica' 'Versicolor' 'Virginica']\n","80     Versicolor\n","45         Setosa\n","144     Virginica\n","110     Virginica\n","38         Setosa\n","2          Setosa\n","135     Virginica\n","72     Versicolor\n","138     Virginica\n","34         Setosa\n","19         Setosa\n","77     Versicolor\n","101     Virginica\n","63     Versicolor\n","117     Virginica\n","Name: target, dtype: object\n","Test Accuracy: 0.933\n","Training Accuracy: 0.983\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Codes\\Python\\Data\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","\n","# Для начала натренируем модель MLPClassifier с параметрами по умолчанию\n","# для тренировочных данных.\n","mlp_classifier = MLPClassifier(random_state=123)\n","mlp_classifier.fit(X_train, Y_train)\n","Y_preds = mlp_classifier.predict(X_test)\n","\n","print(Y_preds[:15])\n","print(Y_test[:15])\n","# Метод score для оценки точности моделей классификации\n","print('Test Accuracy: %.3f' % mlp_classifier.score(X_test, Y_test))\n","print('Training Accuracy: %.3f' % mlp_classifier.score(X_train, Y_train))\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss:  0.2988789340197433\n","Number of Coefs:  2\n","Number of Intercepts:  2\n","Number of Iteration for Which Estimator Ran:  200\n","Name of Output Layer Activation Function:  softmax\n"]}],"source":["\n","# loss_ — возвращает убыток после завершения процесса обучения\n","print('Loss: ', mlp_classifier.loss_)\n","# coefs_ — возвращает массив длины n_layers-1, где каждый элемент представляет веса, связанные с уровнем i\n","print('Number of Coefs: ', len(mlp_classifier.coefs_))\n","# intercepts_ — возвращает массив длины n_layers-1, где каждый элемент представляет собой перехват, связанный с персептронами слоя i\n","print('Number of Intercepts: ', len(mlp_classifier.intercepts_))\n","# n_iter_ — количество итераций, для которых выполнялась оценка\n","print('Number of Iteration for Which Estimator Ran: ', mlp_classifier.n_iter_)\n","# out_activation_ — возвращает имя функции активации выходного слоя.\n","print('Name of Output Layer Activation Function: ', mlp_classifier.out_activation_)"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n"," 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n"," 'Virginica' 'Versicolor' 'Virginica']\n","80     Versicolor\n","45         Setosa\n","144     Virginica\n","110     Virginica\n","38         Setosa\n","2          Setosa\n","135     Virginica\n","72     Versicolor\n","138     Virginica\n","34         Setosa\n","19         Setosa\n","77     Versicolor\n","101     Virginica\n","63     Versicolor\n","117     Virginica\n","Name: target, dtype: object\n","Test Accuracy: 0.933\n","Training Accuracy: 0.983\n","Loss:  0.2988789340197433\n","Number of Coefs:  2\n","Number of Intercepts:  2\n","Number of Iteration for Which Estimator Ran:  200\n","Name of Output Layer Activation Function:  softmax\n"]}],"source":["\n","print(Y_preds[:15])\n","print(Y_test[:15])\n","# Метод score для оценки точности моделей классификации\n","print('Test Accuracy: %.3f' % mlp_classifier.score(X_test, Y_test))\n","print('Training Accuracy: %.3f' % mlp_classifier.score(X_train, Y_train))\n","\n","# loss_ — возвращает убыток после завершения процесса обучения\n","print('Loss: ', mlp_classifier.loss_)\n","# coefs_ — возвращает массив длины n_layers-1, где каждый элемент представляет веса, связанные с уровнем i\n","print('Number of Coefs: ', len(mlp_classifier.coefs_))\n","# intercepts_ — возвращает массив длины n_layers-1, где каждый элемент представляет собой перехват, связанный с персептронами слоя i\n","print('Number of Intercepts: ', len(mlp_classifier.intercepts_))\n","# n_iter_ — количество итераций, для которых выполнялась оценка\n","print('Number of Iteration for Which Estimator Ran: ', mlp_classifier.n_iter_)\n","# out_activation_ — возвращает имя функции активации выходного слоя.\n","print('Name of Output Layer Activation Function: ', mlp_classifier.out_activation_)"]},{"cell_type":"markdown","metadata":{"cell_id":"4f626ccebb61422e890e3cbc73b92d73","deepnote_cell_type":"text-cell-p","formattedRanges":[]},"source":["MLPRegressor — это класс, доступный как часть библиотеки\n","neuro_network sklearn для выполнения задач регрессии с использованием\n","многослойного персептрона."]},{"cell_type":"code","execution_count":71,"metadata":{"cell_id":"7b542308a31047a19fcce31b5e413827","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":224,"execution_start":1686039498157,"source_hash":"7cbe523e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset Size:  (30, 1) (30,)\n","Train/Test size:  (24, 1) (6, 1) (24,) (6,)\n","[20.26234628 55.2781752  18.82135812 50.48274487 20.26234628 50.9622879 ]\n","7      54445.0\n","29    121872.0\n","5      56642.0\n","26    116969.0\n","8      64445.0\n","27    112635.0\n","Name: target, dtype: float64\n","Test R^2 Score: -8.796\n","Training R^2 Score: -8.261\n","Loss:  2988058032.1601596\n","Number of Coefs:  2\n","Number of Intercepts:  2\n","Number of Iteration for Which Estimator Ran:  200\n","Name of Output Layer Activation Function:  identity\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Codes\\Python\\Data\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["url = 'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n","df = pd.read_csv(url)\n","df.head(5)\n","df\n","df = df.rename(columns={'Salary':'target'})\n","X_df, Y_df = df.drop(['target'], axis=1), df.target\n","print ('Dataset Size: ', X_df.shape, Y_df.shape)\n","# Функция train_test_split модуля model_selection sklearn поможет нам\n","# разделить данные на два набора: 80% для обучения и 20% для тестирования.\n","# Мы также используем seed(random_state=123) с train_test_split, чтобы мы\n","# всегда получали одно и то же разделение и могли сравнивать и\n","# воспроизволить результаты в будущем.\n","X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, train_size = 0.80, test_size = 0.20, random_state = 123)\n","print ('Train/Test size: ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n","from sklearn.neural_network import MLPRegressor\n","\n","mlp_regressor = MLPRegressor(random_state=123)\n","mlp_regressor.fit(X_train, Y_train)\n","Y_preds = mlp_regressor.predict(X_test)\n","\n","print (Y_preds[:10])\n","print (Y_test[:10])\n","print ('Test R^2 Score: %.3f'%mlp_regressor.score(X_test, Y_test))\n","print ('Training R^2 Score: %.3f'%mlp_regressor.score(X_train, Y_train))\n","\n","print ('Loss: ', mlp_regressor.loss_)\n","print ('Number of Coefs: ', len(mlp_regressor.coefs_))\n","print ('Number of Intercepts: ', len(mlp_regressor.intercepts_))\n","print ('Number of Iteration for Which Estimator Ran: ', mlp_regressor.n_iter_)\n","print ('Name of Output Layer Activation Function: ', mlp_regressor.out_activation_)\n"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_full_width":true,"deepnote_notebook_id":"af45eb4b309d4ffaa477ee3e1a982ff4","deepnote_persisted_session":{"createdAt":"2023-06-06T08:17:26.006Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
